# webapp/app.py
# -*- coding: utf-8 -*-
import os, io, time, sys, pathlib, json, tempfile, math
import pandas as pd
import streamlit as st

# è®© Python èƒ½æ‰¾åˆ°ä½ çš„ src åŒ…ï¼ˆå‡è®¾ webapp/ ä¸ src/ åŒçº§ï¼‰
ROOT = pathlib.Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

# â€”â€”ä¸¥æ ¼ä½¿ç”¨é¡¹ç›®é‡Œçš„å®ç°ï¼Œä¸åšé¡µé¢çº§å…œåº•/é‡è¯•â€”â€”
from src.chains.description_parser import parse_domains_intents
from src.chains.llm_generators import (
    _ALLOWED_TYPES,              # å…è®¸çš„ç±»å‹é›†åˆ
    gen_for_description_by_types # æ‰¹é‡ç”Ÿæˆå‡½æ•°
)
from src.llm_providers.provider import get_llm  # ä½¿ç”¨ä½ é¡¹ç›®é‡Œçš„ provider

# ============== é¡µé¢åŸºç¡€ä¿¡æ¯ ==============
st.set_page_config(page_title="NLU æµ‹è¯•é›†ç”Ÿæˆå™¨", page_icon="ğŸ§ª", layout="wide")
st.title("ğŸ§ª æµ‹è¯•é›†ç”Ÿæˆå™¨")
st.caption("è¾“å…¥ä¸€å¥è¯/äº§å“æè¿° â†’  ç”Ÿæˆå¤šæ ·åŒ–ä¸­æ–‡æµ‹è¯• Query â†’ ä¸‹è½½ CSV/Parquet")

# ============== ä¾§è¾¹æ å‚æ•°åŒº ==============
with st.sidebar:
    st.header("âš™ï¸ åŸºæœ¬å‚æ•°")

    desc = st.text_area(
        "äº§å“/åœºæ™¯ä¸€å¥è¯æè¿°",
        value="è½¦è½½è¯­éŸ³æ™ºèƒ½åŠ©æ‰‹",
        height=100,
        placeholder="ä¾‹å¦‚ï¼šæ™ºèƒ½å®¶å±…è¯­éŸ³åŠ©æ‰‹ï¼Œæ§åˆ¶ç¯å…‰/ç©ºè°ƒ/æ‰«åœ°æœºå™¨äººï¼Œå«é—²èŠ/ä¸Šä¸‹æ–‡/å®‰å…¨å…œåº•",
        key="inp_desc",
    )

    total = st.number_input(
        "ç›®æ ‡æ€»é‡ï¼ˆæ¡ï¼‰",
        min_value=20, max_value=10000, value=256, step=16,
        key="inp_total",
    )

    # æ˜¯å¦å°† total æŒ‰åŸŸå‡åˆ†ï¼ˆå¼ºçƒˆå»ºè®®æ‰“å¼€ï¼Œé¿å…â€œæ€»é‡Ã—åŸŸæ•°â€çš„è°ƒç”¨æ”¾å¤§ï¼‰
    even_by_domain = st.checkbox(
        "å°†æ€»é‡æŒ‰åŸŸå‡åˆ†ï¼ˆæ¨èï¼‰",
        value=True,
        key="chk_even_by_domain"
    )

    st.markdown("**ç±»å‹é…é¢ï¼ˆæ¯”ä¾‹ 0~1 æˆ–å…·ä½“æ•´æ•°ï¼Œè‡ªåŠ¨å½’ä¸€åˆ°æ€»é‡ï¼‰**")
    default_alloc = {
        "BASE": 0.20, "SYN": 0.20,
        "NOISE": 0.10, "SLANG": 0.10, "DIALECT": 0.10, "TYPO": 0.10,
        "CTX": 0.10, "SAFETY": 0.10
    }
    alloc_inputs = {}
    for i, t in enumerate(["BASE","SYN","NOISE","SLANG","DIALECT","TYPO","CTX","SAFETY"]):
        alloc_inputs[t] = st.text_input(t, value=str(default_alloc[t]), key=f"alloc_{t}_{i}")

    st.divider()
    st.header("ğŸ¤– æ¨¡å‹ä¸é‡‡æ ·")

    MODEL_OPTIONS = {
        "æ»¡è¡€ DeepSeek-R1 (æ¨ç†)": {
            "provider": "deepseek",
            "base_url": "https://ark.cn-beijing.volces.com/api/v3",
            "model": "ep-20250212182831-dgcw4",
        },
        "è±†åŒ… å¤šæ¨¡æ€ Pro": {
            "provider": "doubao",
            "base_url": "https://ark.cn-beijing.volces.com/api/v3",
            "model": "ep-20250508134742-6njfp",
        },
        "è±†åŒ… æ–‡æœ¬ Pro": {
            "provider": "doubao",
            "base_url": "https://ark.cn-beijing.volces.com/api/v3",
            "model": "ep-20250217002939-lfc9n",
        },
    }

    model_choice = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        list(MODEL_OPTIONS.keys()),
        index=0,
        key="sel_model",
    )

    # API Key ç”¨ç¯å¢ƒå˜é‡æˆ–è¿™é‡Œè¾“å…¥ï¼ˆä¼˜å…ˆè¿™é‡Œï¼‰
    api_key_input = st.text_input(
        "API Key",
        type="password",
        value=os.getenv("LLM_API_KEY", ""),
        key="inp_api_key",
        help="å»ºè®®åœ¨éƒ¨ç½²ç¯å¢ƒä½¿ç”¨ Secretsï¼›æœ¬åœ°å¯ export LLM_API_KEYã€‚"
    )

    temperature = st.slider(
        "temperatureï¼ˆé‡‡æ ·å¤šæ ·æ€§ï¼‰",
        min_value=0.0, max_value=1.5,
        value=float(os.getenv("LLM_TEMPERATURE", "0.7")),
        step=0.05,
        key="sld_temp",
    )
    max_tokens = st.number_input(
        "max_tokens",
        min_value=256, max_value=8192,
        value=int(os.getenv("LLM_MAX_TOKENS", "1024")),
        step=128,
        key="inp_max_tokens",
    )

    # é«˜çº§ï¼šæ˜¾ç¤ºæ¯æ¬¡ LLM è°ƒç”¨çš„è¯¦ç»†æ—¥å¿—
    debug_show_logs = st.checkbox("æ˜¾ç¤ºè¯¦ç»†å®æ—¶æ—¥å¿—", value=True, key="chk_debug_logs")

    run_btn = st.button("ğŸš€ ç”Ÿæˆæµ‹è¯•é›†", type="primary", key="btn_run")

# ============== å·¥å…·å‡½æ•° ==============
def resolve_alloc(total_count: int, raw: dict):
    """
    æ”¯æŒæ¯”ä¾‹(0.x)æˆ–å…·ä½“æ•´æ•°ï¼›è‡ªåŠ¨å½’ä¸€åˆ° total_countã€‚
    ä»…ä¿ç•™ _ALLOWED_TYPESï¼Œä¸” >0 çš„æ¡ç›®ã€‚
    """
    # åˆ¤æ–­æ˜¯å¦æŒ‰æ¯”ä¾‹
    is_ratio = True
    try:
        for v in raw.values():
            if float(v) > 1:
                is_ratio = False
                break
    except Exception:
        is_ratio = False

    out = {}
    if is_ratio:
        for k, v in raw.items():
            out[k] = int(round(float(v) * total_count))
        # å››èˆäº”å…¥å·®é¢è¡¥åˆ° BASE
        delta = total_count - sum(out.values())
        out["BASE"] = out.get("BASE", 0) + delta
    else:
        # å…·ä½“æ•´æ•°
        for k, v in raw.items():
            try:
                out[k] = int(float(v))
            except Exception:
                out[k] = 0
        s = sum(out.values())
        if s != total_count and s > 0:
            # æ¯”ä¾‹ç¼©æ”¾åˆ° total_count
            out = {k: int(round(v * total_count / s)) for k, v in out.items()}
            delta = total_count - sum(out.values())
            out["BASE"] = out.get("BASE", 0) + delta

    # åªä¿ç•™å…è®¸çš„ç±»å‹ & >0
    out = {k: v for k, v in out.items() if k in _ALLOWED_TYPES and v > 0}
    return out

def build_cfg(model_choice: str, temperature: float, max_tokens: int, total: int, api_key: str):
    """
    ä» UI æ„é€  cfgï¼Œæ˜¾å¼è¦†ç›– llm ä¿¡æ¯ï¼ˆé¡¹ç›®é‡Œçš„ provider ä¼šå…ˆè¯» cfgï¼Œå†è¯»ç¯å¢ƒå˜é‡ï¼‰ã€‚
    """
    opt = MODEL_OPTIONS[model_choice]
    cfg = {
        "llm": {
            "provider": opt["provider"],  # deepseek / doubaoï¼ˆå†…éƒ¨ç»Ÿä¸€èµ° OpenAI å…¼å®¹ï¼‰
            "model": opt["model"],
            "temperature": float(temperature),
            "max_tokens": int(max_tokens),
            "base_url": opt["base_url"],
        },
        "generation": {
            "total": int(total),
        },
        # ç»™ä¸‹æ¸¸ä¸€ä¸ªè¿è¡Œæ—¶ overrideï¼ˆå¦‚ä½ çš„ provider.py æ”¯æŒï¼Œä¼šç›´æ¥è¯»è¿™é‡Œï¼‰
        "_override": {
            "provider": opt["provider"],
            "model": opt["model"],
            "base_url": opt["base_url"],
            "api_key": api_key.strip(),
            "temperature": float(temperature),
            "max_tokens": int(max_tokens),
        }
    }

    # åŒæ—¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä¿è¯ provider èƒ½è¯»åˆ°ï¼‰
    os.environ["LLM_BASE_URL"] = opt["base_url"]
    os.environ["LLM_MODEL"] = opt["model"]
    if api_key.strip():
        os.environ["LLM_API_KEY"] = api_key.strip()

    return cfg

def log_init():
    if "live_logs" not in st.session_state:
        st.session_state["live_logs"] = []
def log_line(msg: str):
    st.session_state["live_logs"].append(msg)

# ============== ä¸»æµç¨‹ ==============
if run_btn:
    if not desc.strip():
        st.error("è¯·å…ˆå¡«å†™äº§å“/åœºæ™¯æè¿°")
        st.stop()

    # è®¡ç®—ç±»å‹é…é¢ï¼ˆå…¨å±€ï¼‰
    type_counts_global = resolve_alloc(int(total), alloc_inputs)
    if not type_counts_global:
        st.error("è¯·è‡³å°‘ä¸ºä¸€ç§ç±»å‹åˆ†é…æ¡æ•°/æ¯”ä¾‹")
        st.stop()

    # æ„å»º cfgï¼ˆæ˜¾å¼è¦†ç›–åˆ°ä½ é¡¹ç›®çš„ providerï¼‰
    cfg = build_cfg(model_choice, temperature, max_tokens, int(total), api_key_input)

    # === 1) åŸŸè§£æï¼ˆä¸¥æ ¼è°ƒç”¨ä½ é¡¹ç›®é‡Œçš„ parse_domains_intentsï¼‰===
    st.subheader("ğŸ§­ åŸŸè§£æ")
    domain_status = st.empty()
    t0 = time.time()
    taxonomy = parse_domains_intents(cfg, desc)
    domains = taxonomy.get("domains", [])
    domain_names = [d.get("name", "general") for d in domains] or ["general"]
    domain_status.success(f"åŸŸè§£æå®Œæˆï¼š{len(domain_names)} ä¸ª â†’ {', '.join(domain_names)}ï¼ˆç”¨æ—¶ {time.time()-t0:.1f}sï¼‰")
    with st.expander("æŸ¥çœ‹ Domain è§£æ JSON", expanded=False):
        st.json(taxonomy)

    # === 2) è®¡ç®—â€œæ¯ä¸ªåŸŸâ€çš„ç±»å‹é…é¢ ===
    if even_by_domain:
        # æŠŠæ€»é‡æŒ‰åŸŸå‡åˆ†ï¼Œå†æŒ‰ç±»å‹æ‹†åˆ†
        per_domain_total = max(1, int(round(total / len(domain_names))))
        type_counts = resolve_alloc(per_domain_total, alloc_inputs)
        st.caption(f"ğŸ’¡ å·²å¯ç”¨â€œæŒ‰åŸŸå‡åˆ†â€ï¼šæ¯ä¸ªåŸŸç›®æ ‡â‰ˆ {per_domain_total} æ¡ï¼›æ¯åŸŸç±»å‹é…é¢={type_counts}")
    else:
        # ä¸ºæ¯ä¸ªåŸŸä½¿ç”¨â€œå…¨å±€é…é¢â€ï¼ˆä¼šä¹˜ä»¥åŸŸæ•°ï¼‰
        type_counts = type_counts_global
        st.caption(f"âš ï¸ æœªå¯ç”¨â€œæŒ‰åŸŸå‡åˆ†â€ï¼šæ¯ä¸ªåŸŸéƒ½ä½¿ç”¨å…¨å±€é…é¢ï¼›å®é™…æ€»è°ƒç”¨â‰ˆ åŸŸæ•°Ã—ç±»å‹æ•°")

    # === 3) æŒ‰åŸŸ & ç±»å‹ç”Ÿæˆï¼ˆå®æ—¶è¿›åº¦ + è¯¦ç»†æ—¥å¿—ï¼‰===
    st.subheader("ğŸ› ï¸ ç”¨ä¾‹ç”Ÿæˆ")
    progress_overall = st.progress(0, text="å‡†å¤‡ä¸­â€¦")
    per_domain_status = st.empty()
    per_type_status = st.empty()
    log_init()
    if debug_show_logs:
        log_area = st.empty()

    call_metrics = []  # è®°å½•æ¯ä¸ªåŸŸ/ç±»å‹è°ƒç”¨çš„æŒ‡æ ‡

    all_rows = []
    total_domains = len(domain_names)
    total_types_per_domain = len(type_counts)
    total_calls = total_domains # Each domain will now make one call to gen_for_description_by_types
    call_done = 0

    for i, d in enumerate(domain_names, start=1):
        per_domain_status.info(f"åŸŸ [{i}/{total_domains}]ï¼š{d}")
        d_desc = f"{desc}ï¼ˆåŠŸèƒ½åŸŸï¼š{d}ï¼‰"

        t_start = time.perf_counter()
        per_type_status.info(f"  â†³ æ­£åœ¨ä¸ºåŸŸ {d} ç”Ÿæˆæ‰€æœ‰ç±»å‹â€¦")

        # â€”â€”å…³é”®ï¼šè°ƒç”¨ gen_for_description_by_types è·å¾—æ‰€æœ‰ç±»å‹çº§ç»Ÿè®¡â€”â€”
        # å‡è®¾ gen_for_description_by_types è¿”å›çš„ rows å·²ç»åŒ…å«äº† domain ä¿¡æ¯
        rows = gen_for_description_by_types(cfg, d_desc, type_counts)
        all_rows.extend(rows)

        t_used = time.perf_counter() - t_start
        got = len(rows)
        tps = (got / t_used) if t_used > 0 else 0.0
        call_done += 1
        progress_overall.progress(
            min(100, int(call_done * 100 / max(1, total_calls))),
            text=f"å·²å®Œæˆ {call_done}/{total_calls} æ¬¡åŸŸè°ƒç”¨"
        )

        # Simplified metrics for domain-level call
        call_metrics.append({
            "domain": d,
            "need_total": sum(type_counts.values()),
            "got_total": got,
            "time_sec": round(t_used, 2),
            "tps": round(tps, 2),
        })

        if debug_show_logs:
            log_line(f"[{d}] ç›®æ ‡ {sum(type_counts.values())} â†’ å®å¾— {got}ï¼›è€—æ—¶ {t_used:.2f}sï¼Œåå {tps:.2f} q/s")
            log_area.code("\n".join(st.session_state["live_logs"]), language="text")

        per_domain_status.success(f"åŸŸ {d} å®Œæˆã€‚")

    per_type_status.empty()
    progress_overall.progress(100, text="å…¨éƒ¨å®Œæˆ")

    # === 4) æ±‡æ€»å±•ç¤º ===
    st.success(f"âœ… ç”Ÿæˆå®Œæˆï¼Œå…± {len(all_rows)} æ¡")
    if not all_rows:
        st.error("æ²¡æœ‰ç”Ÿæˆåˆ°æ ·æœ¬ï¼Œè¯·æ£€æŸ¥ Key/ç½‘ç»œ/æ¨¡å‹ã€‚")
        st.stop()

    df = pd.DataFrame(all_rows)

    # === 5) ç»Ÿè®¡é¢æ¿ ===
    st.subheader("ğŸ“Š ç»Ÿè®¡")
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        st.metric("æ€»æ¡æ•°", len(df))
    with c2:
        st.metric("åŸŸæ•°é‡", df["domain"].nunique())
    with c3:
        st.metric("ç±»å‹æ•°é‡", df["test_type"].nunique())
    with c4:
        st.metric("æ€»è°ƒç”¨æ¬¡æ•°", total_calls)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown("**ç±»å‹åˆ†å¸ƒ**")
        st.dataframe(
            df["test_type"].value_counts().rename_axis("test_type").reset_index(name="count"),
            use_container_width=True
        )
    with col2:
        st.markdown("**Domain åˆ†å¸ƒ**")
        st.dataframe(
            df["domain"].fillna("general").value_counts().rename_axis("domain").reset_index(name="count"),
            use_container_width=True
        )

    st.markdown("**è°ƒç”¨æ˜ç»†ï¼ˆåŸŸ Ã— ç±»å‹ï¼‰**")
    df_calls = pd.DataFrame(call_metrics)
    st.dataframe(df_calls, use_container_width=True)

    st.subheader("ğŸ” é¢„è§ˆï¼ˆTop 100ï¼‰")
    st.dataframe(df.head(100), use_container_width=True, height=420)

    # === 6) ä¸‹è½½åŒº ===
    st.subheader("â¬‡ï¸ ä¸‹è½½")
    # CSV
    csv_buf = io.StringIO()
    df.to_csv(csv_buf, index=False, encoding="utf-8-sig")
    st.download_button("ä¸‹è½½ CSV", data=csv_buf.getvalue(), file_name="testcases.csv", mime="text/csv", key="dl_csv")

    # Parquetï¼ˆéœ€è¦ pyarrowï¼‰
    try:
        import pyarrow as pa, pyarrow.parquet as pq
        with tempfile.NamedTemporaryFile(suffix=".parquet", delete=False) as tmpf:
            table = pa.Table.from_pandas(df)
            pq.write_table(table, tmpf.name)
            tmp_path = tmpf.name
        with open(tmp_path, "rb") as f:
            st.download_button("ä¸‹è½½ Parquet", data=f.read(), file_name="testcases.parquet",
                               mime="application/octet-stream", key="dl_parquet")
        os.remove(tmp_path)
    except Exception:
        st.info("å¦‚éœ€ Parquet ä¸‹è½½ï¼Œè¯·åœ¨ requirements.txt ä¸­æ·»åŠ  `pyarrow`ã€‚")
